{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer Recap: Data Analysis with Pandas\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Review fundamental pandas operations for data manipulation and analysis.\n",
    "* Apply data cleaning techniques to real-world social science datasets.\n",
    "* Practice exploratory data analysis using descriptive statistics and basic visualizations.\n",
    "* Demonstrate ability to filter, group, and aggregate data using pandas methods.\n",
    "* Evaluate LLM-generated code for accuracy and best practices.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "ü§ñ **AI Generated**: Code generated by an LLM that we'll test and debug.<br>\n",
    "\n",
    "### Sections\n",
    "1. [Data Loading and Initial Exploration](#section1)\n",
    "2. [Data Cleaning and Basic Operations](#section2)\n",
    "3. [Exploratory Data Analysis](#section3)\n",
    "4. [Text Analysis Fundamentals](#section4)\n",
    "5. [Working with LLM-Generated Code](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "# Data Loading and Initial Exploration\n",
    "\n",
    "Today we'll work with data from Reddit's \"Am I the Asshole?\" (AITA) subreddit. This dataset contains posts where people describe situations and ask for community judgment about their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../../data/aita_top_subs.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 1: Data Overview\n",
    "\n",
    "Explore the dataset structure and provide a summary of what you find. Use pandas methods to:\n",
    "1. Check the data types of each column\n",
    "2. Look for missing values\n",
    "3. Get basic descriptive statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What do you notice about the `selftext` column? What might this tell us about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "\n",
    "# Data Cleaning and Basic Operations\n",
    "\n",
    "Real-world data often requires cleaning before analysis. Let's examine our dataset for common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate posts\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Look at the distribution of some key variables\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(df['score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 2: Data Cleaning\n",
    "\n",
    "Clean the dataset by:\n",
    "1. Removing any posts where `selftext` is missing or empty\n",
    "2. Creating a new column called `text_length` that contains the character count of `selftext`\n",
    "3. Filter out posts that are shorter than 100 characters (likely low-quality posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.len()` method to get string lengths in pandas. Remember that missing values might cause issues, so handle them first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Dates\n",
    "\n",
    "The `created` column contains Unix timestamps. Let's convert these to readable dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created'], unit='s')\n",
    "\n",
    "# Extract useful date components\n",
    "df['year'] = df['created_date'].dt.year\n",
    "df['month'] = df['created_date'].dt.month\n",
    "df['day_of_week'] = df['created_date'].dt.day_name()\n",
    "\n",
    "print(\"Date range in dataset:\")\n",
    "print(f\"From: {df['created_date'].min()}\")\n",
    "print(f\"To: {df['created_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "Now let's explore patterns in the data using pandas grouping and aggregation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 3: Score Analysis\n",
    "\n",
    "Analyze post popularity by:\n",
    "1. Finding the top 10 posts by score\n",
    "2. Calculating the average score by year\n",
    "3. Determining which day of the week gets the highest average scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Engagement Analysis\n",
    "\n",
    "Now, let's explore how users interact with posts by analyzing the volume and distribution of comments, which can highlight engagement patterns and community response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between text length and engagement\n",
    "correlation = df[['text_length', 'score', 'num_comments']].corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What does the correlation tell us about the relationship between post length and engagement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 4: Engagement Categories\n",
    "\n",
    "Create engagement categories and analyze them:\n",
    "1. Create a new column `engagement_level` with categories:\n",
    "   - 'Low': score < 4000\n",
    "   - 'Medium': score 4000-6000\n",
    "   - 'High': score 6000-10000\n",
    "   - 'Viral': score > 20000\n",
    "2. Calculate the percentage of posts in each category\n",
    "3. Find the average text length for each engagement level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "# Text Analysis Fundamentals\n",
    "\n",
    "Let's do some basic text analysis to understand the content patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 5: Text Pattern Analysis\n",
    "\n",
    "Analyze text patterns by:\n",
    "1. Finding posts that contain the word \"family\" (case-insensitive)\n",
    "2. Counting how many posts mention \"wedding\" or \"marriage\"\n",
    "3. Creating a column indicating whether the post is about relationships (contains words like \"boyfriend\", \"girlfriend\", \"husband\", \"wife\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.contains()` method with pandas to search for text patterns. The `case=False` parameter makes the search case-insensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Analysis\n",
    "\n",
    "Let's examine the authors. Do authors post multiple times? If so, who posts the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze posting patterns by author\n",
    "author_stats = df['author'].value_counts().head(10)\n",
    "print(\"Top 10 most active authors:\")\n",
    "print(author_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 6: Final Analysis\n",
    "\n",
    "Combine multiple pandas operations to answer this question:\n",
    "**\"What are the characteristics of the most engaging posts about relationships?\"**\n",
    "\n",
    "Create an analysis that:\n",
    "1. Filters for relationship-related posts\n",
    "2. Groups them by engagement level\n",
    "3. Calculates average text length, comment count, and any other relevant metrics\n",
    "4. Presents a clear summary of your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning**: When working with text data, always be mindful of missing values and different text encodings that might cause unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* Pandas provides powerful tools for loading, cleaning, and exploring real-world datasets.\n",
    "* Always start data analysis by understanding your dataset structure and checking for data quality issues.\n",
    "* The `.groupby()` method is essential for aggregating data and finding patterns across categories.\n",
    "* Text data requires special handling, including case-insensitive searches and pattern matching.\n",
    "* Correlation analysis helps identify relationships between numerical variables.\n",
    "* Creating categorical variables from continuous data enables different types of analysis.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
