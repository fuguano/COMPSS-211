{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer Recap: Data Analysis with Pandas\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Review fundamental pandas operations for data manipulation and analysis.\n",
    "* Apply data cleaning techniques to real-world social science datasets.\n",
    "* Practice exploratory data analysis using descriptive statistics and basic visualizations.\n",
    "* Demonstrate ability to filter, group, and aggregate data using pandas methods.\n",
    "* Evaluate LLM-generated code for accuracy and best practices.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "ü§ñ **AI Generated**: Code generated by an LLM that we'll test and debug.<br>\n",
    "\n",
    "### Sections\n",
    "1. [Data Loading and Initial Exploration](#section1)\n",
    "2. [Data Cleaning and Basic Operations](#section2)\n",
    "3. [Exploratory Data Analysis](#section3)\n",
    "4. [Text Analysis Fundamentals](#section4)\n",
    "5. [Working with LLM-Generated Code](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "# Data Loading and Initial Exploration\n",
    "\n",
    "Today we'll work with data from Reddit's \"Am I the Asshole?\" (AITA) subreddit. This dataset contains posts where people describe situations and ask for community judgment about their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 23)\n",
      "\n",
      "Column names:\n",
      "['idint', 'idstr', 'created', 'self', 'nsfw', 'author', 'title', 'url', 'selftext', 'score', 'subreddit', 'distinguish', 'textlen', 'num_comments', 'flair_text', 'flair_css_class', 'augmented_at', 'augmented_count', 'created_date', 'year', 'month', 'day_of_week', 'text_length']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../../data/aita_top_subs.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>self</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>augmented_at</th>\n",
       "      <th>augmented_count</th>\n",
       "      <th>created_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>797709732</td>\n",
       "      <td>t3_d6xoro</td>\n",
       "      <td>1568998300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DarthCharizard</td>\n",
       "      <td>META: This sub is moving towards a value syste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I‚Äôve enjoyed reading and posting on this sub f...</td>\n",
       "      <td>80915.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6215.0</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-20 16:51:40</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1472895100</td>\n",
       "      <td>t3_ocx94s</td>\n",
       "      <td>1625315782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OnlyInQuebec9</td>\n",
       "      <td>AITA for telling my wife the lock on my daught...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My brother in-law (Sammy) lost his home shortl...</td>\n",
       "      <td>80334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5318.0</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>not</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-03 12:36:22</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664921441</td>\n",
       "      <td>t3_azvko1</td>\n",
       "      <td>1552322462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Renegadesrule33</td>\n",
       "      <td>UPDATE, AITA for despising my mentally handica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm back like I said I would be,. My [original...</td>\n",
       "      <td>72776.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>UPDATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-11 16:41:02</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855862814</td>\n",
       "      <td>t3_e5k3z2</td>\n",
       "      <td>1575392873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>throwRA-fhfsveyary</td>\n",
       "      <td>AITA for pretending to get fired when customer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am a high schooler with a weekend job at a c...</td>\n",
       "      <td>63526.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3645.0</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>not</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-03 17:07:53</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>756636047</td>\n",
       "      <td>t3_cihc3z</td>\n",
       "      <td>1564233111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thunderbear998</td>\n",
       "      <td>AITA for telling my extended family how many m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We had a family dinner this evening. My family...</td>\n",
       "      <td>54132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>Everyone Sucks</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-27 13:11:51</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idint      idstr     created  self  nsfw              author  \\\n",
       "0   797709732  t3_d6xoro  1568998300   1.0   0.0      DarthCharizard   \n",
       "1  1472895100  t3_ocx94s  1625315782   1.0   0.0       OnlyInQuebec9   \n",
       "2   664921441  t3_azvko1  1552322462   1.0   0.0     Renegadesrule33   \n",
       "3   855862814  t3_e5k3z2  1575392873   1.0   0.0  throwRA-fhfsveyary   \n",
       "4   756636047  t3_cihc3z  1564233111   1.0   0.0      Thunderbear998   \n",
       "\n",
       "                                               title  url  \\\n",
       "0  META: This sub is moving towards a value syste...  NaN   \n",
       "1  AITA for telling my wife the lock on my daught...  NaN   \n",
       "2  UPDATE, AITA for despising my mentally handica...  NaN   \n",
       "3  AITA for pretending to get fired when customer...  NaN   \n",
       "4  AITA for telling my extended family how many m...  NaN   \n",
       "\n",
       "                                            selftext    score  ...  \\\n",
       "0  I‚Äôve enjoyed reading and posting on this sub f...  80915.0  ...   \n",
       "1  My brother in-law (Sammy) lost his home shortl...  80334.0  ...   \n",
       "2  I'm back like I said I would be,. My [original...  72776.0  ...   \n",
       "3  I am a high schooler with a weekend job at a c...  63526.0  ...   \n",
       "4  We had a family dinner this evening. My family...  54132.0  ...   \n",
       "\n",
       "  num_comments      flair_text  flair_css_class  augmented_at augmented_count  \\\n",
       "0       6215.0            META              NaN           NaN             NaN   \n",
       "1       5318.0  Not the A-hole              not           NaN             NaN   \n",
       "2       1989.0          UPDATE              NaN           NaN             NaN   \n",
       "3       3645.0  Not the A-hole              not           NaN             NaN   \n",
       "4       5190.0  Everyone Sucks              ass           NaN             NaN   \n",
       "\n",
       "          created_date  year  month day_of_week  text_length  \n",
       "0  2019-09-20 16:51:40  2019      9      Friday       3266.0  \n",
       "1  2021-07-03 12:36:22  2021      7    Saturday       2664.0  \n",
       "2  2019-03-11 16:41:02  2019      3      Monday       5437.0  \n",
       "3  2019-12-03 17:07:53  2019     12     Tuesday       2096.0  \n",
       "4  2019-07-27 13:11:51  2019      7    Saturday       1662.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 1: Data Overview\n",
    "\n",
    "Explore the dataset structure and provide a summary of what you find. Use pandas methods to:\n",
    "1. Check the data types of each column\n",
    "2. Look for missing values\n",
    "3. Get basic descriptive statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Types:\n",
      "idint                int64\n",
      "idstr               object\n",
      "created              int64\n",
      "self               float64\n",
      "nsfw               float64\n",
      "author              object\n",
      "title               object\n",
      "url                float64\n",
      "selftext            object\n",
      "score              float64\n",
      "subreddit           object\n",
      "distinguish         object\n",
      "textlen            float64\n",
      "num_comments       float64\n",
      "flair_text          object\n",
      "flair_css_class     object\n",
      "augmented_at       float64\n",
      "augmented_count    float64\n",
      "created_date        object\n",
      "year                 int64\n",
      "month                int64\n",
      "day_of_week         object\n",
      "text_length        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE (3 parts/code cells)\n",
    "\n",
    "# 1. Check the data types\n",
    "print(\"Column Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values per Column:\n",
      "idint                  0\n",
      "idstr                  0\n",
      "created                0\n",
      "self                   0\n",
      "nsfw                   0\n",
      "author                 0\n",
      "title                  0\n",
      "url                10000\n",
      "selftext               4\n",
      "score                  0\n",
      "subreddit              0\n",
      "distinguish         9999\n",
      "textlen                0\n",
      "num_comments           0\n",
      "flair_text          1175\n",
      "flair_css_class     1441\n",
      "augmented_at       10000\n",
      "augmented_count    10000\n",
      "created_date           0\n",
      "year                   0\n",
      "month                  0\n",
      "day_of_week            0\n",
      "text_length            4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Missing values\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "              idint       created     self          nsfw  url         score  \\\n",
      "count  1.000000e+04  1.000000e+04  10000.0  10000.000000  0.0  10000.000000   \n",
      "mean   1.213800e+09  1.604749e+09      1.0      0.005300  NaN  10137.508500   \n",
      "std    2.832943e+08  2.370645e+07      0.0      0.072612  NaN   6987.893464   \n",
      "min    5.826428e+08  1.539143e+09      1.0      0.000000  NaN   3739.000000   \n",
      "25%    1.003247e+09  1.589699e+09      1.0      0.000000  NaN   5168.750000   \n",
      "50%    1.224636e+09  1.607434e+09      1.0      0.000000  NaN   7437.000000   \n",
      "75%    1.472430e+09  1.625272e+09      1.0      0.000000  NaN  13128.250000   \n",
      "max    1.662312e+09  1.639655e+09      1.0      1.000000  NaN  80915.000000   \n",
      "\n",
      "           textlen  num_comments  augmented_at  augmented_count          year  \\\n",
      "count  10000.00000  10000.000000           0.0              0.0  10000.000000   \n",
      "mean    1878.93120   1218.262500           NaN              NaN   2020.303200   \n",
      "std      830.80909    946.524966           NaN              NaN      0.737105   \n",
      "min        0.00000    321.000000           NaN              NaN   2018.000000   \n",
      "25%     1347.00000    591.000000           NaN              NaN   2020.000000   \n",
      "50%     1934.00000    911.000000           NaN              NaN   2020.000000   \n",
      "75%     2532.00000   1505.000000           NaN              NaN   2021.000000   \n",
      "max     7750.00000  10265.000000           NaN              NaN   2021.000000   \n",
      "\n",
      "              month   text_length  \n",
      "count  10000.000000   9996.000000  \n",
      "mean       7.098600   1924.839236  \n",
      "std        3.330734   1305.271474  \n",
      "min        1.000000      1.000000  \n",
      "25%        5.000000   1146.000000  \n",
      "50%        7.000000   1971.000000  \n",
      "75%       10.000000   2756.000000  \n",
      "max       12.000000  15084.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Descriptive Stats\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What do you notice about the `selftext` column? What might this tell us about the data?\n",
    "* In this column, values are 1.0 and reading as an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       I‚Äôve enjoyed reading and posting on this sub f...\n",
      "1       My brother in-law (Sammy) lost his home shortl...\n",
      "2       I'm back like I said I would be,. My [original...\n",
      "3       I am a high schooler with a weekend job at a c...\n",
      "4       We had a family dinner this evening. My family...\n",
      "                              ...                        \n",
      "9995    This is so stupid. I can‚Äôt believe I‚Äôm even po...\n",
      "9996                                            [removed]\n",
      "9997    \\nI divorced my wife shortly after our 11 year...\n",
      "9998    My younger sister is getting married to my ex ...\n",
      "9999    We visit my ILs a lot. Way too much, IMHO. But...\n",
      "Name: selftext, Length: 10000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"selftext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([1865, 2177, 3516, 7246], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"selftext\"].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "\n",
    "# Data Cleaning and Basic Operations\n",
    "\n",
    "Real-world data often requires cleaning before analysis. Let's examine our dataset for common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "\n",
      "Score statistics:\n",
      "count    10000.000000\n",
      "mean     10137.508500\n",
      "std       6987.893464\n",
      "min       3739.000000\n",
      "25%       5168.750000\n",
      "50%       7437.000000\n",
      "75%      13128.250000\n",
      "max      80915.000000\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate posts\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Look at the distribution of some key variables\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(df['score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 2: Data Cleaning\n",
    "\n",
    "Clean the dataset by:\n",
    "1. Removing any posts where `selftext` is missing or empty\n",
    "2. Creating a new column called `text_length` that contains the character count of `selftext`\n",
    "3. Filter out posts that are shorter than 100 characters (likely low-quality posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           idint      idstr     created  self  nsfw                author  \\\n",
      "0      797709732  t3_d6xoro  1568998300   1.0   0.0        DarthCharizard   \n",
      "1     1472895100  t3_ocx94s  1625315782   1.0   0.0         OnlyInQuebec9   \n",
      "2      664921441  t3_azvko1  1552322462   1.0   0.0       Renegadesrule33   \n",
      "3      855862814  t3_e5k3z2  1575392873   1.0   0.0    throwRA-fhfsveyary   \n",
      "4      756636047  t3_cihc3z  1564233111   1.0   0.0        Thunderbear998   \n",
      "...          ...        ...         ...   ...   ...                   ...   \n",
      "9995  1095380546  t3_i45t1e  1596635860   1.0   0.0            Zodiac1031   \n",
      "9996  1240844365  t3_kirln1  1608723816   1.0   0.0       throwaway447282   \n",
      "9997  1606282878  t3_qkc7su  1635767270   1.0   0.0          ThePorch2021   \n",
      "9998  1590272785  t3_qat2c1  1634582579   1.0   0.0  1_OfChamberlains_20k   \n",
      "9999   896555134  t3_etsada  1579967163   1.0   0.0              lilybee_   \n",
      "\n",
      "                                                  title  url  \\\n",
      "0     META: This sub is moving towards a value syste...  NaN   \n",
      "1     AITA for telling my wife the lock on my daught...  NaN   \n",
      "2     UPDATE, AITA for despising my mentally handica...  NaN   \n",
      "3     AITA for pretending to get fired when customer...  NaN   \n",
      "4     AITA for telling my extended family how many m...  NaN   \n",
      "...                                                 ...  ...   \n",
      "9995  AITA for telling my husband we can‚Äôt take our ...  NaN   \n",
      "9996         AITA for not wearing a bra in my own home?  NaN   \n",
      "9997  AITA for telling my son's stepfather that I'll...  NaN   \n",
      "9998  AITA for not going to my sisters wedding, beca...  NaN   \n",
      "9999  AITA if I refuse to let my in-laws take my bab...  NaN   \n",
      "\n",
      "                                               selftext    score  ...  \\\n",
      "0     I‚Äôve enjoyed reading and posting on this sub f...  80915.0  ...   \n",
      "1     My brother in-law (Sammy) lost his home shortl...  80334.0  ...   \n",
      "2     I'm back like I said I would be,. My [original...  72776.0  ...   \n",
      "3     I am a high schooler with a weekend job at a c...  63526.0  ...   \n",
      "4     We had a family dinner this evening. My family...  54132.0  ...   \n",
      "...                                                 ...      ...  ...   \n",
      "9995  This is so stupid. I can‚Äôt believe I‚Äôm even po...   3742.0  ...   \n",
      "9996                                          [removed]   3742.0  ...   \n",
      "9997  \\nI divorced my wife shortly after our 11 year...   3741.0  ...   \n",
      "9998  My younger sister is getting married to my ex ...   3740.0  ...   \n",
      "9999  We visit my ILs a lot. Way too much, IMHO. But...   3739.0  ...   \n",
      "\n",
      "     num_comments      flair_text  flair_css_class  augmented_at  \\\n",
      "0          6215.0            META              NaN           NaN   \n",
      "1          5318.0  Not the A-hole              not           NaN   \n",
      "2          1989.0          UPDATE              NaN           NaN   \n",
      "3          3645.0  Not the A-hole              not           NaN   \n",
      "4          5190.0  Everyone Sucks              ass           NaN   \n",
      "...           ...             ...              ...           ...   \n",
      "9995        549.0  Not the A-hole              not           NaN   \n",
      "9996        870.0  Not the A-hole              not           NaN   \n",
      "9997        406.0  Not the A-hole              not           NaN   \n",
      "9998        612.0  Not the A-hole              not           NaN   \n",
      "9999        663.0  Not the A-hole              not           NaN   \n",
      "\n",
      "     augmented_count         created_date  year  month day_of_week  \\\n",
      "0                NaN  2019-09-20 16:51:40  2019      9      Friday   \n",
      "1                NaN  2021-07-03 12:36:22  2021      7    Saturday   \n",
      "2                NaN  2019-03-11 16:41:02  2019      3      Monday   \n",
      "3                NaN  2019-12-03 17:07:53  2019     12     Tuesday   \n",
      "4                NaN  2019-07-27 13:11:51  2019      7    Saturday   \n",
      "...              ...                  ...   ...    ...         ...   \n",
      "9995             NaN  2020-08-05 13:57:40  2020      8   Wednesday   \n",
      "9996             NaN  2020-12-23 11:43:36  2020     12   Wednesday   \n",
      "9997             NaN  2021-11-01 11:47:50  2021     11      Monday   \n",
      "9998             NaN  2021-10-18 18:42:59  2021     10      Monday   \n",
      "9999             NaN  2020-01-25 15:46:03  2020      1    Saturday   \n",
      "\n",
      "      text_length  \n",
      "0          3266.0  \n",
      "1          2664.0  \n",
      "2          5437.0  \n",
      "3          2096.0  \n",
      "4          1662.0  \n",
      "...           ...  \n",
      "9995       3785.0  \n",
      "9996          9.0  \n",
      "9997       2608.0  \n",
      "9998        489.0  \n",
      "9999        744.0  \n",
      "\n",
      "[9996 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Remove posts where selftext is missing or empty\n",
    "df2 = df[df[\"selftext\"].notnull()]          # remove NaN\n",
    "df2 = df2[df2[\"selftext\"].str.strip() != \"\"]  # remove empty strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3266\n",
      "1       2664\n",
      "2       5437\n",
      "3       2096\n",
      "4       1662\n",
      "        ... \n",
      "9995    3785\n",
      "9996       9\n",
      "9997    2608\n",
      "9998     489\n",
      "9999     744\n",
      "Name: text_length, Length: 9996, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. New column - text length\n",
    "df2[\"text_length\"] = df2[\"selftext\"].str.len()\n",
    "print(df2[\"text_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter out shorter than 100 characters\n",
    "df2 = df2[df2[\"text_length\"] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        idint      idstr     created  self  nsfw              author  \\\n",
      "0   797709732  t3_d6xoro  1568998300   1.0   0.0      DarthCharizard   \n",
      "1  1472895100  t3_ocx94s  1625315782   1.0   0.0       OnlyInQuebec9   \n",
      "2   664921441  t3_azvko1  1552322462   1.0   0.0     Renegadesrule33   \n",
      "3   855862814  t3_e5k3z2  1575392873   1.0   0.0  throwRA-fhfsveyary   \n",
      "4   756636047  t3_cihc3z  1564233111   1.0   0.0      Thunderbear998   \n",
      "\n",
      "                                               title  url  \\\n",
      "0  META: This sub is moving towards a value syste...  NaN   \n",
      "1  AITA for telling my wife the lock on my daught...  NaN   \n",
      "2  UPDATE, AITA for despising my mentally handica...  NaN   \n",
      "3  AITA for pretending to get fired when customer...  NaN   \n",
      "4  AITA for telling my extended family how many m...  NaN   \n",
      "\n",
      "                                            selftext    score  ...  \\\n",
      "0  I‚Äôve enjoyed reading and posting on this sub f...  80915.0  ...   \n",
      "1  My brother in-law (Sammy) lost his home shortl...  80334.0  ...   \n",
      "2  I'm back like I said I would be,. My [original...  72776.0  ...   \n",
      "3  I am a high schooler with a weekend job at a c...  63526.0  ...   \n",
      "4  We had a family dinner this evening. My family...  54132.0  ...   \n",
      "\n",
      "  num_comments      flair_text  flair_css_class  augmented_at augmented_count  \\\n",
      "0       6215.0            META              NaN           NaN             NaN   \n",
      "1       5318.0  Not the A-hole              not           NaN             NaN   \n",
      "2       1989.0          UPDATE              NaN           NaN             NaN   \n",
      "3       3645.0  Not the A-hole              not           NaN             NaN   \n",
      "4       5190.0  Everyone Sucks              ass           NaN             NaN   \n",
      "\n",
      "          created_date  year  month day_of_week  text_length  \n",
      "0  2019-09-20 16:51:40  2019      9      Friday         3266  \n",
      "1  2021-07-03 12:36:22  2021      7    Saturday         2664  \n",
      "2  2019-03-11 16:41:02  2019      3      Monday         5437  \n",
      "3  2019-12-03 17:07:53  2019     12     Tuesday         2096  \n",
      "4  2019-07-27 13:11:51  2019      7    Saturday         1662  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Final cleaned dataset\n",
    "print(df2.head())\n",
    "# print(\"\\nRemaining rows:\", len(df2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.len()` method to get string lengths in pandas. Remember that missing values might cause issues, so handle them first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Dates\n",
    "\n",
    "The `created` column contains Unix timestamps. Let's convert these to readable dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in dataset:\n",
      "From: 2018-10-10 03:39:34\n",
      "To: 2021-12-16 11:46:38\n"
     ]
    }
   ],
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created'], unit='s')\n",
    "\n",
    "# Extract useful date components\n",
    "df['year'] = df['created_date'].dt.year\n",
    "df['month'] = df['created_date'].dt.month\n",
    "df['day_of_week'] = df['created_date'].dt.day_name()\n",
    "\n",
    "print(\"Date range in dataset:\")\n",
    "print(f\"From: {df['created_date'].min()}\")\n",
    "print(f\"To: {df['created_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "Now let's explore patterns in the data using pandas grouping and aggregation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 3: Score Analysis\n",
    "\n",
    "Analyze post popularity by:\n",
    "1. Finding the top 10 posts by score\n",
    "2. Calculating the average score by year\n",
    "3. Determining which day of the week gets the highest average scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 posts by score:\n",
      "     score                                           selftext\n",
      "0  80915.0  I‚Äôve enjoyed reading and posting on this sub f...\n",
      "1  80334.0  My brother in-law (Sammy) lost his home shortl...\n",
      "2  72776.0  I'm back like I said I would be,. My [original...\n",
      "3  63526.0  I am a high schooler with a weekend job at a c...\n",
      "4  54132.0  We had a family dinner this evening. My family...\n",
      "5  51323.0  My aunt and uncle are paying for my cousins co...\n",
      "6  49967.0  \\n\\n\\nContext: My sister (F27) and I (18F) los...\n",
      "7  48572.0  (reposted with mod approval)\\n\\nOriginal post:...\n",
      "8  47893.0   Link to original post-  [https://www.reddit.c...\n",
      "9  47771.0  So my son had a long-distance gf recently for ...\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "top10_posts = df2.nlargest(10, \"score\")\n",
    "print(\"Top 10 posts by score:\")\n",
    "print(top10_posts[[\"score\", \"selftext\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average score by year:\n",
      "year\n",
      "2018     8178.867647\n",
      "2019    12185.123024\n",
      "2020    10356.536883\n",
      "2021     9338.448843\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df2[\"created_date\"] = pd.to_datetime(df2[\"created_date\"], errors=\"coerce\")\n",
    "\n",
    "df2[\"year\"] = df2[\"created_date\"].dt.year\n",
    "avg_score_by_year = df2.groupby(\"year\")[\"score\"].mean().sort_index()\n",
    "print(\"\\nAverage score by year:\")\n",
    "print(avg_score_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Engagement Analysis\n",
    "\n",
    "Now, let's explore how users interact with posts by analyzing the volume and distribution of comments, which can highlight engagement patterns and community response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between text length and engagement\n",
    "correlation = df[['text_length', 'score', 'num_comments']].corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What does the correlation tell us about the relationship between post length and engagement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 4: Engagement Categories\n",
    "\n",
    "Create engagement categories and analyze them:\n",
    "1. Create a new column `engagement_level` with categories:\n",
    "   - 'Low': score < 4000\n",
    "   - 'Medium': score 4000-6000\n",
    "   - 'High': score 6000-10000\n",
    "   - 'Viral': score > 20000\n",
    "2. Calculate the percentage of posts in each category\n",
    "3. Find the average text length for each engagement level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "# Text Analysis Fundamentals\n",
    "\n",
    "Let's do some basic text analysis to understand the content patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 5: Text Pattern Analysis\n",
    "\n",
    "Analyze text patterns by:\n",
    "1. Finding posts that contain the word \"family\" (case-insensitive)\n",
    "2. Counting how many posts mention \"wedding\" or \"marriage\"\n",
    "3. Creating a column indicating whether the post is about relationships (contains words like \"boyfriend\", \"girlfriend\", \"husband\", \"wife\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.contains()` method with pandas to search for text patterns. The `case=False` parameter makes the search case-insensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Analysis\n",
    "\n",
    "Let's examine the authors. Do authors post multiple times? If so, who posts the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze posting patterns by author\n",
    "author_stats = df['author'].value_counts().head(10)\n",
    "print(\"Top 10 most active authors:\")\n",
    "print(author_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 6: Final Analysis\n",
    "\n",
    "Combine multiple pandas operations to answer this question:\n",
    "**\"What are the characteristics of the most engaging posts about relationships?\"**\n",
    "\n",
    "Create an analysis that:\n",
    "1. Filters for relationship-related posts\n",
    "2. Groups them by engagement level\n",
    "3. Calculates average text length, comment count, and any other relevant metrics\n",
    "4. Presents a clear summary of your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning**: When working with text data, always be mindful of missing values and different text encodings that might cause unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* Pandas provides powerful tools for loading, cleaning, and exploring real-world datasets.\n",
    "* Always start data analysis by understanding your dataset structure and checking for data quality issues.\n",
    "* The `.groupby()` method is essential for aggregating data and finding patterns across categories.\n",
    "* Text data requires special handling, including case-insensitive searches and pattern matching.\n",
    "* Correlation analysis helps identify relationships between numerical variables.\n",
    "* Creating categorical variables from continuous data enables different types of analysis.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
